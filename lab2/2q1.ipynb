{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNTIME = 00:00:02\n",
      "+----+-------+-----+\n",
      "|year|station|value|\n",
      "+----+-------+-----+\n",
      "|2013| 102170|-13.3|\n",
      "|1957| 102190|-19.9|\n",
      "|1959| 102190|-23.2|\n",
      "|1961| 102190|-23.5|\n",
      "|2014| 102170|-24.3|\n",
      "|1955| 102190|-26.2|\n",
      "|1958| 102190|-27.9|\n",
      "|1960| 102190|-28.3|\n",
      "|1956| 102190|-30.0|\n",
      "+----+-------+-----+\n",
      "\n",
      "None\n",
      "+----+-------+-----+\n",
      "|year|station|value|\n",
      "+----+-------+-----+\n",
      "|2013| 102170|-13.3|\n",
      "|1957| 102190|-19.9|\n",
      "|1959| 102190|-23.2|\n",
      "|1961| 102190|-23.5|\n",
      "|2014| 102170|-24.3|\n",
      "|1955| 102190|-26.2|\n",
      "|1958| 102190|-27.9|\n",
      "|1960| 102190|-28.3|\n",
      "|1956| 102190|-30.0|\n",
      "+----+-------+-----+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "sc.stop()\n",
    "\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "rdd = sc.textFile(\"temperature-readings-tiny.csv\")\n",
    "parts = rdd.map(lambda l: l.split(\";\"))\n",
    "df = parts.map(lambda p: Row(year=p[1].split(\"-\")[0], value=float(p[3]),station=int(p[0]) ))\n",
    "\n",
    "df = sqlContext.createDataFrame(df)\t\n",
    "df.registerTempTable(\"tempReadings\")\n",
    "\n",
    "df1 = df.filter(df.year.between(1950,2014))\n",
    "df2 = df.groupBy(\"year\",).agg({\"value\":\"max\"}).withColumnRenamed(\"max(value)\",\"value\")\n",
    "df2 = df2.join(df1, [\"year\",\"value\"],\"inner\").select(\"year\", \"station\", \"value\")\n",
    "df2 = df2.dropDuplicates([\"year\"])\n",
    "df2 = df2.sort(df2.value.desc())\n",
    "\n",
    "df3 = df.groupBy(\"year\",).agg({\"value\":\"min\"}).withColumnRenamed(\"min(value)\",\"value\")\n",
    "df3 = df3.join(df1, [\"year\",\"value\"],\"inner\").select(\"year\", \"station\", \"value\")\n",
    "df3 = df3.dropDuplicates([\"year\"])\n",
    "df3 = df3.sort(df3.value.desc())\n",
    "\n",
    "# max_temperatureSorted = df2.rdd\n",
    "# min_temperatureSorted = df3.rdd\n",
    "\n",
    "# max_temperatureSorted.saveAsTextFile(\"./results2/2q1/max_temperatureSorted\")\n",
    "# min_temperatureSorted.saveAsTextFile(\"./results2/2q1/min_temperatureSorted\")\n",
    "\n",
    "end = time.time()\n",
    "final_time = time.strftime('%H:%M:%S', time.gmtime(end-start))\n",
    "\n",
    "print (\"RUNTIME = \" + final_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
