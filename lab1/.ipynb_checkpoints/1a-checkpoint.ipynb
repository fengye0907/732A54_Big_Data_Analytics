{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "sc.stop()\n",
    "def max_temperature(a,b):\n",
    "    if a>=b:\n",
    "        return a\n",
    "    else:\n",
    "        return b\n",
    "def min_temperature(a,b):\n",
    "    if a>=b:\n",
    "        return b\n",
    "    else:\n",
    "        return a\n",
    "sc = SparkContext(appName=\"exercise\")\n",
    "\n",
    "# read csv file\n",
    "temperature_file=sc.textFile(\"temperature-readings-tiny.csv\")\n",
    "lines = temperature_file.map(lambda line:line.split(\";\"))\n",
    "# print(*lines.take(1000), sep='\\n')\n",
    "\n",
    "# all the temperatures from 1950 to 2014\n",
    "# make 'station number' and 'temperature' as a multi-value\n",
    "year_temperature = lines.map(lambda x:(x[1][0:4],(float(x[3]),int(x[0]))))\n",
    "year_temperature = year_temperature.filter(lambda x: int(x[0])>=1950 and int(x[0])<=2014)\n",
    "\n",
    "# year_temperature = year_temperature.filter(lambda x: int(x[0][1])==102170 and int(x[0][0])==2014)\n",
    "# print(*year_temperature.take(10), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2014', (40.0, 102160))\n",
      "('1960', (29.0, 102190))\n",
      "('1959', (28.2, 102190))\n",
      "('1958', (28.1, 102190))\n",
      "('1956', (26.0, 102190))\n",
      "('1957', (25.2, 102190))\n",
      "('1955', (20.4, 102190))\n",
      "('1961', (19.0, 102190))\n",
      "('2013', (10.2, 102170))\n",
      "================================================\n",
      "('2013', (-13.3, 102170))\n",
      "('1957', (-19.9, 102190))\n",
      "('1959', (-23.2, 102190))\n",
      "('1961', (-23.5, 102190))\n",
      "('2014', (-24.3, 102170))\n",
      "('1955', (-26.2, 102190))\n",
      "('1958', (-27.9, 102190))\n",
      "('1960', (-28.3, 102190))\n",
      "('1956', (-30.0, 102190))\n"
     ]
    }
   ],
   "source": [
    "# reduce 'max_temperature' by key 'year', it will also work on value 'stations number'\n",
    "max_temperature = year_temperature.reduceByKey(max_temperature)\n",
    "max_temperatureSorted = max_temperature.sortBy(ascending = False, keyfunc=lambda k:k[1])\n",
    "print(*max_temperatureSorted.take(64),sep=\"\\n\")\n",
    "print('================================================')\n",
    "min_temperature = year_temperature.reduceByKey(min_temperature)\n",
    "min_temperatureSorted = min_temperature.sortBy(ascending = False, keyfunc=lambda k:k[1])\n",
    "print(*min_temperatureSorted.take(64),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use logging (add the --conf spark.eventLog.enabled=true flag) to check the execution of the Spark program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
